{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-23T05:11:31.320527Z",
     "iopub.status.busy": "2025-08-23T05:11:31.319960Z",
     "iopub.status.idle": "2025-08-23T08:11:23.291924Z",
     "shell.execute_reply": "2025-08-23T08:11:23.291060Z",
     "shell.execute_reply.started": "2025-08-23T05:11:31.320499Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hTotal: 1875 image-mask pairs\n",
      "Train: 1312, Val: 281, Test: 282\n",
      "\n",
      "ğŸš€ Training with encoder: resnet34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb552f7a2ab43028e537ed8fc3f6cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2577a02b1a471988fd843cc8836995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RESNET34 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3284 | Val Loss: 1.0450\n",
      "Epoch 02/20 | Train Loss: 0.9049 | Val Loss: 0.7865\n",
      "Epoch 03/20 | Train Loss: 0.6251 | Val Loss: 0.6311\n",
      "Epoch 04/20 | Train Loss: 0.4697 | Val Loss: 0.4226\n",
      "Epoch 05/20 | Train Loss: 0.3639 | Val Loss: 0.4319\n",
      "Epoch 06/20 | Train Loss: 0.2972 | Val Loss: 0.3517\n",
      "Epoch 07/20 | Train Loss: 0.2521 | Val Loss: 0.3731\n",
      "Epoch 08/20 | Train Loss: 0.2274 | Val Loss: 0.3596\n",
      "Epoch 09/20 | Train Loss: 0.1958 | Val Loss: 0.3229\n",
      "Epoch 10/20 | Train Loss: 0.1769 | Val Loss: 0.3051\n",
      "Epoch 11/20 | Train Loss: 0.1773 | Val Loss: 0.3455\n",
      "Epoch 12/20 | Train Loss: 0.1582 | Val Loss: 0.3190\n",
      "Epoch 13/20 | Train Loss: 0.1438 | Val Loss: 0.3324\n",
      "Epoch 14/20 | Train Loss: 0.1396 | Val Loss: 0.3422\n",
      "Epoch 15/20 | Train Loss: 0.1437 | Val Loss: 0.4510\n",
      "Epoch 16/20 | Train Loss: 0.1733 | Val Loss: 0.6629\n",
      "Epoch 17/20 | Train Loss: 0.1759 | Val Loss: 0.3269\n",
      "Epoch 18/20 | Train Loss: 0.1368 | Val Loss: 0.3875\n",
      "Epoch 19/20 | Train Loss: 0.1228 | Val Loss: 0.3499\n",
      "Epoch 20/20 | Train Loss: 0.1109 | Val Loss: 0.3442\n",
      "\n",
      "ğŸš€ Training with encoder: resnet50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d4c4dba8e54ec6969c9668d66b3a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8501add650c04dee83e80da8db371a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/102M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RESNET50 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.2535 | Val Loss: 0.9260\n",
      "Epoch 02/20 | Train Loss: 0.7822 | Val Loss: 0.6472\n",
      "Epoch 03/20 | Train Loss: 0.5695 | Val Loss: 0.5413\n",
      "Epoch 04/20 | Train Loss: 0.4615 | Val Loss: 0.4242\n",
      "Epoch 05/20 | Train Loss: 0.3298 | Val Loss: 0.3937\n",
      "Epoch 06/20 | Train Loss: 0.2901 | Val Loss: 0.3623\n",
      "Epoch 07/20 | Train Loss: 0.2698 | Val Loss: 0.7403\n",
      "Epoch 08/20 | Train Loss: 0.3128 | Val Loss: 0.3819\n",
      "Epoch 09/20 | Train Loss: 0.2318 | Val Loss: 0.3058\n",
      "Epoch 10/20 | Train Loss: 0.1837 | Val Loss: 0.2922\n",
      "Epoch 11/20 | Train Loss: 0.1651 | Val Loss: 0.3210\n",
      "Epoch 12/20 | Train Loss: 0.1961 | Val Loss: 0.3652\n",
      "Epoch 13/20 | Train Loss: 0.1851 | Val Loss: 0.3775\n",
      "Epoch 14/20 | Train Loss: 0.1600 | Val Loss: 0.3000\n",
      "Epoch 15/20 | Train Loss: 0.1333 | Val Loss: 0.3469\n",
      "Epoch 16/20 | Train Loss: 0.1328 | Val Loss: 0.3899\n",
      "Epoch 17/20 | Train Loss: 0.1385 | Val Loss: 0.3887\n",
      "Epoch 18/20 | Train Loss: 0.1175 | Val Loss: 0.3561\n",
      "Epoch 19/20 | Train Loss: 0.1081 | Val Loss: 0.3425\n",
      "Epoch 20/20 | Train Loss: 0.0995 | Val Loss: 0.3964\n",
      "\n",
      "ğŸš€ Training with encoder: densenet121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb0c1c8aaf8403bae973420613deef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87e55d024394490838a7fb4d93766d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/32.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training DENSENET121 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.1369 | Val Loss: 0.7682\n",
      "Epoch 02/20 | Train Loss: 0.6207 | Val Loss: 0.5192\n",
      "Epoch 03/20 | Train Loss: 0.4227 | Val Loss: 0.4503\n",
      "Epoch 04/20 | Train Loss: 0.3117 | Val Loss: 0.3766\n",
      "Epoch 05/20 | Train Loss: 0.2724 | Val Loss: 0.3495\n",
      "Epoch 06/20 | Train Loss: 0.2266 | Val Loss: 0.3338\n",
      "Epoch 07/20 | Train Loss: 0.2041 | Val Loss: 0.3634\n",
      "Epoch 08/20 | Train Loss: 0.1866 | Val Loss: 0.3645\n",
      "Epoch 09/20 | Train Loss: 0.1730 | Val Loss: 0.3526\n",
      "Epoch 10/20 | Train Loss: 0.1581 | Val Loss: 0.3523\n",
      "Epoch 11/20 | Train Loss: 0.1830 | Val Loss: 0.3224\n",
      "Epoch 12/20 | Train Loss: 0.1577 | Val Loss: 0.3173\n",
      "Epoch 13/20 | Train Loss: 0.1411 | Val Loss: 0.3706\n",
      "Epoch 14/20 | Train Loss: 0.1289 | Val Loss: 0.3821\n",
      "Epoch 15/20 | Train Loss: 0.1593 | Val Loss: 0.3228\n",
      "Epoch 16/20 | Train Loss: 0.1427 | Val Loss: 0.3925\n",
      "Epoch 17/20 | Train Loss: 0.1468 | Val Loss: 0.3931\n",
      "Epoch 18/20 | Train Loss: 0.1298 | Val Loss: 0.3243\n",
      "Epoch 19/20 | Train Loss: 0.1153 | Val Loss: 0.3609\n",
      "Epoch 20/20 | Train Loss: 0.1613 | Val Loss: 0.3396\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9caeb6620aa54ea1b849052bce7c5605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1817825c29b54b5d8844445c0ed1a585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B0 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3490 | Val Loss: 1.5135\n",
      "Epoch 02/20 | Train Loss: 0.7746 | Val Loss: 1.0216\n",
      "Epoch 03/20 | Train Loss: 0.5359 | Val Loss: 0.6044\n",
      "Epoch 04/20 | Train Loss: 0.4048 | Val Loss: 0.4646\n",
      "Epoch 05/20 | Train Loss: 0.3375 | Val Loss: 0.4698\n",
      "Epoch 06/20 | Train Loss: 0.2954 | Val Loss: 0.3585\n",
      "Epoch 07/20 | Train Loss: 0.2567 | Val Loss: 0.3348\n",
      "Epoch 08/20 | Train Loss: 0.2385 | Val Loss: 0.3323\n",
      "Epoch 09/20 | Train Loss: 0.2080 | Val Loss: 0.3832\n",
      "Epoch 10/20 | Train Loss: 0.1985 | Val Loss: 0.3463\n",
      "Epoch 11/20 | Train Loss: 0.1915 | Val Loss: 0.3215\n",
      "Epoch 12/20 | Train Loss: 0.1805 | Val Loss: 0.3337\n",
      "Epoch 13/20 | Train Loss: 0.1749 | Val Loss: 0.3097\n",
      "Epoch 14/20 | Train Loss: 0.1682 | Val Loss: 0.3596\n",
      "Epoch 15/20 | Train Loss: 0.1823 | Val Loss: 0.3233\n",
      "Epoch 16/20 | Train Loss: 0.1533 | Val Loss: 0.3518\n",
      "Epoch 17/20 | Train Loss: 0.1454 | Val Loss: 0.3396\n",
      "Epoch 18/20 | Train Loss: 0.1405 | Val Loss: 0.3647\n",
      "Epoch 19/20 | Train Loss: 0.1404 | Val Loss: 0.3856\n",
      "Epoch 20/20 | Train Loss: 0.1298 | Val Loss: 0.3742\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c45d4b91a7244c868b080418b51cae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e343bbd022ce44ec83ac5f50926142c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/31.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B1 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.4085 | Val Loss: 1.3458\n",
      "Epoch 02/20 | Train Loss: 0.8409 | Val Loss: 0.7543\n",
      "Epoch 03/20 | Train Loss: 0.6120 | Val Loss: 0.6626\n",
      "Epoch 04/20 | Train Loss: 0.4528 | Val Loss: 0.5399\n",
      "Epoch 05/20 | Train Loss: 0.3725 | Val Loss: 0.5083\n",
      "Epoch 06/20 | Train Loss: 0.3210 | Val Loss: 0.3859\n",
      "Epoch 07/20 | Train Loss: 0.2852 | Val Loss: 0.3484\n",
      "Epoch 08/20 | Train Loss: 0.2429 | Val Loss: 0.3389\n",
      "Epoch 09/20 | Train Loss: 0.2225 | Val Loss: 0.3396\n",
      "Epoch 10/20 | Train Loss: 0.2025 | Val Loss: 0.3070\n",
      "Epoch 11/20 | Train Loss: 0.1941 | Val Loss: 0.3541\n",
      "Epoch 12/20 | Train Loss: 0.1795 | Val Loss: 0.3872\n",
      "Epoch 13/20 | Train Loss: 0.1712 | Val Loss: 0.3418\n",
      "Epoch 14/20 | Train Loss: 0.1650 | Val Loss: 0.3145\n",
      "Epoch 15/20 | Train Loss: 0.1605 | Val Loss: 0.3283\n",
      "Epoch 16/20 | Train Loss: 0.1526 | Val Loss: 0.3276\n",
      "Epoch 17/20 | Train Loss: 0.1431 | Val Loss: 0.3274\n",
      "Epoch 18/20 | Train Loss: 0.1391 | Val Loss: 0.3611\n",
      "Epoch 19/20 | Train Loss: 0.1336 | Val Loss: 0.3232\n",
      "Epoch 20/20 | Train Loss: 0.1295 | Val Loss: 0.3333\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f588b831127e4b06817bab78629bf826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68354fe4deb94c13a034a073dfd4977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/36.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B2 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.4013 | Val Loss: 1.2404\n",
      "Epoch 02/20 | Train Loss: 0.7732 | Val Loss: 0.8526\n",
      "Epoch 03/20 | Train Loss: 0.5495 | Val Loss: 0.5659\n",
      "Epoch 04/20 | Train Loss: 0.4135 | Val Loss: 0.4497\n",
      "Epoch 05/20 | Train Loss: 0.3393 | Val Loss: 0.4147\n",
      "Epoch 06/20 | Train Loss: 0.2841 | Val Loss: 0.3358\n",
      "Epoch 07/20 | Train Loss: 0.2527 | Val Loss: 0.3189\n",
      "Epoch 08/20 | Train Loss: 0.2370 | Val Loss: 0.3732\n",
      "Epoch 09/20 | Train Loss: 0.2132 | Val Loss: 0.3142\n",
      "Epoch 10/20 | Train Loss: 0.2019 | Val Loss: 0.3174\n",
      "Epoch 11/20 | Train Loss: 0.1834 | Val Loss: 0.3214\n",
      "Epoch 12/20 | Train Loss: 0.1712 | Val Loss: 0.3196\n",
      "Epoch 13/20 | Train Loss: 0.1610 | Val Loss: 0.3605\n",
      "Epoch 14/20 | Train Loss: 0.1601 | Val Loss: 0.3360\n",
      "Epoch 15/20 | Train Loss: 0.1472 | Val Loss: 0.3417\n",
      "Epoch 16/20 | Train Loss: 0.1389 | Val Loss: 0.3432\n",
      "Epoch 17/20 | Train Loss: 0.1474 | Val Loss: 0.3138\n",
      "Epoch 18/20 | Train Loss: 0.1340 | Val Loss: 0.3104\n",
      "Epoch 19/20 | Train Loss: 0.1310 | Val Loss: 0.3158\n",
      "Epoch 20/20 | Train Loss: 0.1255 | Val Loss: 0.3179\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0c5fcfeedb47da949d269ec2732ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e4dccfe8314d7e8ed96e3705a6277e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B3 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3243 | Val Loss: 1.0960\n",
      "Epoch 02/20 | Train Loss: 0.7770 | Val Loss: 0.7430\n",
      "Epoch 03/20 | Train Loss: 0.5392 | Val Loss: 0.5196\n",
      "Epoch 04/20 | Train Loss: 0.3874 | Val Loss: 0.4273\n",
      "Epoch 05/20 | Train Loss: 0.3135 | Val Loss: 0.3648\n",
      "Epoch 06/20 | Train Loss: 0.2698 | Val Loss: 0.3215\n",
      "Epoch 07/20 | Train Loss: 0.2409 | Val Loss: 0.3498\n",
      "Epoch 08/20 | Train Loss: 0.2134 | Val Loss: 0.3344\n",
      "Epoch 09/20 | Train Loss: 0.1946 | Val Loss: 0.3262\n",
      "Epoch 10/20 | Train Loss: 0.1770 | Val Loss: 0.3555\n",
      "Epoch 11/20 | Train Loss: 0.1652 | Val Loss: 0.3269\n",
      "Epoch 12/20 | Train Loss: 0.1632 | Val Loss: 0.3266\n",
      "Epoch 13/20 | Train Loss: 0.1486 | Val Loss: 0.3330\n",
      "Epoch 14/20 | Train Loss: 0.1426 | Val Loss: 0.3053\n",
      "Epoch 15/20 | Train Loss: 0.1361 | Val Loss: 0.3206\n",
      "Epoch 16/20 | Train Loss: 0.1328 | Val Loss: 0.3025\n",
      "Epoch 17/20 | Train Loss: 0.1280 | Val Loss: 0.3244\n",
      "Epoch 18/20 | Train Loss: 0.1263 | Val Loss: 0.3104\n",
      "Epoch 19/20 | Train Loss: 0.1188 | Val Loss: 0.3233\n",
      "Epoch 20/20 | Train Loss: 0.1135 | Val Loss: 0.3332\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53753f1def8f43ceb0e41106fff878bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbf3f90bb5944db98c8daee1e13ddf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/77.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B4 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3313 | Val Loss: 1.1084\n",
      "Epoch 02/20 | Train Loss: 0.7592 | Val Loss: 0.7447\n",
      "Epoch 03/20 | Train Loss: 0.5038 | Val Loss: 0.5739\n",
      "Epoch 04/20 | Train Loss: 0.3746 | Val Loss: 0.4463\n",
      "Epoch 05/20 | Train Loss: 0.3049 | Val Loss: 0.3652\n",
      "Epoch 06/20 | Train Loss: 0.2605 | Val Loss: 0.3570\n",
      "Epoch 07/20 | Train Loss: 0.2238 | Val Loss: 0.3282\n",
      "Epoch 08/20 | Train Loss: 0.1980 | Val Loss: 0.3170\n",
      "Epoch 09/20 | Train Loss: 0.1814 | Val Loss: 0.3209\n",
      "Epoch 10/20 | Train Loss: 0.1681 | Val Loss: 0.3262\n",
      "Epoch 11/20 | Train Loss: 0.1556 | Val Loss: 0.3188\n",
      "Epoch 12/20 | Train Loss: 0.1487 | Val Loss: 0.3156\n",
      "Epoch 13/20 | Train Loss: 0.1447 | Val Loss: 0.3341\n",
      "Epoch 14/20 | Train Loss: 0.1397 | Val Loss: 0.3095\n",
      "Epoch 15/20 | Train Loss: 0.1310 | Val Loss: 0.3315\n",
      "Epoch 16/20 | Train Loss: 0.1214 | Val Loss: 0.3707\n",
      "Epoch 17/20 | Train Loss: 0.1183 | Val Loss: 0.3503\n",
      "Epoch 18/20 | Train Loss: 0.1148 | Val Loss: 0.3370\n",
      "Epoch 19/20 | Train Loss: 0.1123 | Val Loss: 0.3462\n",
      "Epoch 20/20 | Train Loss: 0.1064 | Val Loss: 0.3405\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6c9b468e2148938050530128eb8a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4569ec3ed94066bf1751992e96586d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B5 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3449 | Val Loss: 0.9511\n",
      "Epoch 02/20 | Train Loss: 0.7630 | Val Loss: 0.7002\n",
      "Epoch 03/20 | Train Loss: 0.5314 | Val Loss: 0.5602\n",
      "Epoch 04/20 | Train Loss: 0.3945 | Val Loss: 0.4434\n",
      "Epoch 05/20 | Train Loss: 0.3108 | Val Loss: 0.3769\n",
      "Epoch 06/20 | Train Loss: 0.2549 | Val Loss: 0.3232\n",
      "Epoch 07/20 | Train Loss: 0.2228 | Val Loss: 0.3273\n",
      "Epoch 08/20 | Train Loss: 0.1950 | Val Loss: 0.3073\n",
      "Epoch 09/20 | Train Loss: 0.1764 | Val Loss: 0.2899\n",
      "Epoch 10/20 | Train Loss: 0.1654 | Val Loss: 0.2993\n",
      "Epoch 11/20 | Train Loss: 0.1518 | Val Loss: 0.3021\n",
      "Epoch 12/20 | Train Loss: 0.1405 | Val Loss: 0.3030\n",
      "Epoch 13/20 | Train Loss: 0.1332 | Val Loss: 0.2946\n",
      "Epoch 14/20 | Train Loss: 0.1271 | Val Loss: 0.2910\n",
      "Epoch 15/20 | Train Loss: 0.1210 | Val Loss: 0.3152\n",
      "Epoch 16/20 | Train Loss: 0.1165 | Val Loss: 0.3118\n",
      "Epoch 17/20 | Train Loss: 0.1119 | Val Loss: 0.3033\n",
      "Epoch 18/20 | Train Loss: 0.1086 | Val Loss: 0.2836\n",
      "Epoch 19/20 | Train Loss: 0.1047 | Val Loss: 0.3114\n",
      "Epoch 20/20 | Train Loss: 0.1027 | Val Loss: 0.3054\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af39b35b2c3d429ab974184439afb37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee836e43a174145b5f712e640083af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/173M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B6 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.4448 | Val Loss: 1.1130\n",
      "Epoch 02/20 | Train Loss: 0.8848 | Val Loss: 0.7960\n",
      "Epoch 03/20 | Train Loss: 0.6099 | Val Loss: 0.6342\n",
      "Epoch 04/20 | Train Loss: 0.4396 | Val Loss: 0.4628\n",
      "Epoch 05/20 | Train Loss: 0.3356 | Val Loss: 0.3822\n",
      "Epoch 06/20 | Train Loss: 0.2769 | Val Loss: 0.3358\n",
      "Epoch 07/20 | Train Loss: 0.2253 | Val Loss: 0.3420\n",
      "Epoch 08/20 | Train Loss: 0.1973 | Val Loss: 0.3382\n",
      "Epoch 09/20 | Train Loss: 0.1825 | Val Loss: 0.3143\n",
      "Epoch 10/20 | Train Loss: 0.1601 | Val Loss: 0.3194\n",
      "Epoch 11/20 | Train Loss: 0.1456 | Val Loss: 0.3048\n",
      "Epoch 12/20 | Train Loss: 0.1355 | Val Loss: 0.3195\n",
      "Epoch 13/20 | Train Loss: 0.1326 | Val Loss: 0.3274\n",
      "Epoch 14/20 | Train Loss: 0.1284 | Val Loss: 0.2905\n",
      "Epoch 15/20 | Train Loss: 0.1165 | Val Loss: 0.3017\n",
      "Epoch 16/20 | Train Loss: 0.1131 | Val Loss: 0.3126\n",
      "Epoch 17/20 | Train Loss: 0.1080 | Val Loss: 0.3190\n",
      "Epoch 18/20 | Train Loss: 0.1023 | Val Loss: 0.3113\n",
      "Epoch 19/20 | Train Loss: 0.0992 | Val Loss: 0.3102\n",
      "Epoch 20/20 | Train Loss: 0.0945 | Val Loss: 0.3195\n",
      "\n",
      "ğŸš€ Training with encoder: efficientnet-b7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597b740f8ac34281b60481498a58a278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69039dd34e3483d89a99e45a9f8350c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/267M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training EFFICIENTNET-B7 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3417 | Val Loss: 1.0949\n",
      "Epoch 02/20 | Train Loss: 0.7339 | Val Loss: 0.6402\n",
      "Epoch 03/20 | Train Loss: 0.5009 | Val Loss: 0.5391\n",
      "Epoch 04/20 | Train Loss: 0.3643 | Val Loss: 0.3982\n",
      "Epoch 05/20 | Train Loss: 0.2922 | Val Loss: 0.3979\n",
      "Epoch 06/20 | Train Loss: 0.2416 | Val Loss: 0.3531\n",
      "Epoch 07/20 | Train Loss: 0.2073 | Val Loss: 0.3587\n",
      "Epoch 08/20 | Train Loss: 0.1803 | Val Loss: 0.3109\n",
      "Epoch 09/20 | Train Loss: 0.1615 | Val Loss: 0.3148\n",
      "Epoch 10/20 | Train Loss: 0.1459 | Val Loss: 0.3199\n",
      "Epoch 11/20 | Train Loss: 0.1418 | Val Loss: 0.3231\n",
      "Epoch 12/20 | Train Loss: 0.1312 | Val Loss: 0.3232\n",
      "Epoch 13/20 | Train Loss: 0.1217 | Val Loss: 0.3254\n",
      "Epoch 14/20 | Train Loss: 0.1157 | Val Loss: 0.3393\n",
      "Epoch 15/20 | Train Loss: 0.1304 | Val Loss: 0.3515\n",
      "Epoch 16/20 | Train Loss: 0.1241 | Val Loss: 0.3289\n",
      "Epoch 17/20 | Train Loss: 0.1113 | Val Loss: 0.3416\n",
      "Epoch 18/20 | Train Loss: 0.1040 | Val Loss: 0.3261\n",
      "Epoch 19/20 | Train Loss: 0.0958 | Val Loss: 0.3390\n",
      "Epoch 20/20 | Train Loss: 0.0928 | Val Loss: 0.3330\n",
      "\n",
      "ğŸš€ Training with encoder: vgg19_bn\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc77d8ff9304ecaa98f91efe3aa6ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e498d4f5284f16bb1745504298c1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/575M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training VGG19_BN for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.1919 | Val Loss: 0.7720\n",
      "Epoch 02/20 | Train Loss: 0.6429 | Val Loss: 0.5522\n",
      "Epoch 03/20 | Train Loss: 0.4377 | Val Loss: 0.4487\n",
      "Epoch 04/20 | Train Loss: 0.3825 | Val Loss: 0.3858\n",
      "Epoch 05/20 | Train Loss: 0.3088 | Val Loss: 0.4037\n",
      "Epoch 06/20 | Train Loss: 0.2445 | Val Loss: 0.3187\n",
      "Epoch 07/20 | Train Loss: 0.2047 | Val Loss: 0.3689\n",
      "Epoch 08/20 | Train Loss: 0.1795 | Val Loss: 0.3112\n",
      "Epoch 09/20 | Train Loss: 0.2176 | Val Loss: 0.4066\n",
      "Epoch 10/20 | Train Loss: 0.2231 | Val Loss: 0.2928\n",
      "Epoch 11/20 | Train Loss: 0.1633 | Val Loss: 0.2961\n",
      "Epoch 12/20 | Train Loss: 0.1461 | Val Loss: 0.2987\n",
      "Epoch 13/20 | Train Loss: 0.1318 | Val Loss: 0.3398\n",
      "Epoch 14/20 | Train Loss: 0.1244 | Val Loss: 0.3111\n",
      "Epoch 15/20 | Train Loss: 0.1169 | Val Loss: 0.2991\n",
      "Epoch 16/20 | Train Loss: 0.1249 | Val Loss: 0.6122\n",
      "Epoch 17/20 | Train Loss: 0.2444 | Val Loss: 0.3769\n",
      "Epoch 18/20 | Train Loss: 0.2101 | Val Loss: 0.3578\n",
      "Epoch 19/20 | Train Loss: 0.1706 | Val Loss: 0.3085\n",
      "Epoch 20/20 | Train Loss: 0.1322 | Val Loss: 0.3408\n",
      "\n",
      "ğŸš€ Training with encoder: mobilenet_v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba770fdd6b643428df9ad957fd35ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/106 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efda6679fb864ddebf65dc8af9a66a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training MOBILENET_V2 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.3264 | Val Loss: 0.9845\n",
      "Epoch 02/20 | Train Loss: 0.8244 | Val Loss: 0.7058\n",
      "Epoch 03/20 | Train Loss: 0.5862 | Val Loss: 0.5801\n",
      "Epoch 04/20 | Train Loss: 0.4436 | Val Loss: 0.4694\n",
      "Epoch 05/20 | Train Loss: 0.3561 | Val Loss: 0.3978\n",
      "Epoch 06/20 | Train Loss: 0.2993 | Val Loss: 0.3939\n",
      "Epoch 07/20 | Train Loss: 0.2624 | Val Loss: 0.3383\n",
      "Epoch 08/20 | Train Loss: 0.2346 | Val Loss: 0.3589\n",
      "Epoch 09/20 | Train Loss: 0.2355 | Val Loss: 0.3423\n",
      "Epoch 10/20 | Train Loss: 0.2250 | Val Loss: 0.3539\n",
      "Epoch 11/20 | Train Loss: 0.1950 | Val Loss: 0.3660\n",
      "Epoch 12/20 | Train Loss: 0.1730 | Val Loss: 0.3420\n",
      "Epoch 13/20 | Train Loss: 0.1624 | Val Loss: 0.3781\n",
      "Epoch 14/20 | Train Loss: 0.1517 | Val Loss: 0.3530\n",
      "Epoch 15/20 | Train Loss: 0.1450 | Val Loss: 0.4044\n",
      "Epoch 16/20 | Train Loss: 0.1784 | Val Loss: 0.3624\n",
      "Epoch 17/20 | Train Loss: 0.1627 | Val Loss: 0.3135\n",
      "Epoch 18/20 | Train Loss: 0.1587 | Val Loss: 0.4074\n",
      "Epoch 19/20 | Train Loss: 0.1519 | Val Loss: 0.3537\n",
      "Epoch 20/20 | Train Loss: 0.1401 | Val Loss: 0.4090\n",
      "\n",
      "ğŸš€ Training with encoder: mit_b0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0ff87d8f644274a64317b24ea28244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7243aaa2c041efb27c8389252e2ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/14.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training MIT_B0 for 20 epochs ===\n",
      "Epoch 01/20 | Train Loss: 1.4211 | Val Loss: 1.0316\n",
      "Epoch 02/20 | Train Loss: 0.9487 | Val Loss: 0.7676\n",
      "Epoch 03/20 | Train Loss: 0.7221 | Val Loss: 0.6233\n",
      "Epoch 04/20 | Train Loss: 0.5694 | Val Loss: 0.4973\n",
      "Epoch 05/20 | Train Loss: 0.4499 | Val Loss: 0.4251\n",
      "Epoch 06/20 | Train Loss: 0.3595 | Val Loss: 0.3756\n",
      "Epoch 07/20 | Train Loss: 0.3294 | Val Loss: 0.3645\n",
      "Epoch 08/20 | Train Loss: 0.2751 | Val Loss: 0.3387\n",
      "Epoch 09/20 | Train Loss: 0.2556 | Val Loss: 0.3125\n",
      "Epoch 10/20 | Train Loss: 0.2386 | Val Loss: 0.3187\n",
      "Epoch 11/20 | Train Loss: 0.2053 | Val Loss: 0.3194\n",
      "Epoch 12/20 | Train Loss: 0.2173 | Val Loss: 0.3261\n",
      "Epoch 13/20 | Train Loss: 0.2292 | Val Loss: 0.3272\n",
      "Epoch 14/20 | Train Loss: 0.1880 | Val Loss: 0.3999\n",
      "Epoch 15/20 | Train Loss: 0.1717 | Val Loss: 0.4327\n",
      "Epoch 16/20 | Train Loss: 0.1614 | Val Loss: 0.3729\n",
      "Epoch 17/20 | Train Loss: 0.1579 | Val Loss: 0.3193\n",
      "Epoch 18/20 | Train Loss: 0.1576 | Val Loss: 0.3309\n",
      "Epoch 19/20 | Train Loss: 0.1420 | Val Loss: 0.3501\n",
      "Epoch 20/20 | Train Loss: 0.2320 | Val Loss: 0.3701\n",
      "\n",
      "ğŸ“Š Final Comparison Results:\n",
      "              Model  Precision    Recall        F1       IoU      Dice  \\\n",
      "0          resnet34   0.862067  0.931353  0.894179  0.812428  0.894179   \n",
      "1          resnet50   0.856371  0.925362  0.887263  0.800932  0.887263   \n",
      "2       densenet121   0.838130  0.942843  0.886006  0.798904  0.886006   \n",
      "3   efficientnet-b0   0.872274  0.921118  0.894679  0.812366  0.894679   \n",
      "4   efficientnet-b1   0.852346  0.936455  0.891188  0.806483  0.891189   \n",
      "5   efficientnet-b2   0.831386  0.942530  0.882039  0.792393  0.882039   \n",
      "6   efficientnet-b3   0.865991  0.938829  0.899887  0.820157  0.899887   \n",
      "7   efficientnet-b4   0.843303  0.942751  0.889387  0.804084  0.889387   \n",
      "8   efficientnet-b5   0.859186  0.938759  0.896289  0.815080  0.896289   \n",
      "9   efficientnet-b6   0.853989  0.944066  0.896103  0.814796  0.896104   \n",
      "10  efficientnet-b7   0.856635  0.945711  0.898080  0.817187  0.898080   \n",
      "11         vgg19_bn   0.856541  0.930771  0.891181  0.807751  0.891181   \n",
      "12     mobilenet_v2   0.833301  0.937217  0.881133  0.790296  0.881133   \n",
      "13           mit_b0   0.801586  0.948900  0.866297  0.769450  0.866297   \n",
      "\n",
      "    Accuracy  \n",
      "0   0.980557  \n",
      "1   0.979741  \n",
      "2   0.978727  \n",
      "3   0.981435  \n",
      "4   0.980019  \n",
      "5   0.978074  \n",
      "6   0.981740  \n",
      "7   0.979915  \n",
      "8   0.981245  \n",
      "9   0.980855  \n",
      "10  0.981267  \n",
      "11  0.980351  \n",
      "12  0.977802  \n",
      "13  0.973987  \n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# =========================\n",
    "# Reproducibility\n",
    "# =========================\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "# =========================\n",
    "# Dataset\n",
    "# =========================\n",
    "class BUSIDataset(Dataset):\n",
    "    def __init__(self, df, resize=(256, 256)):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.resize = resize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx][\"image\"]\n",
    "        mask_path = self.df.iloc[idx][\"mask\"]\n",
    "\n",
    "        # Load\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        # Resize\n",
    "        if self.resize is not None:\n",
    "            img = img.resize(self.resize)\n",
    "            mask = mask.resize(self.resize)\n",
    "\n",
    "        # To numpy\n",
    "        img = np.array(img, dtype=np.float32) / 255.0\n",
    "        mask = (np.array(mask, dtype=np.float32) / 255.0)\n",
    "        mask = (mask > 0.5).astype(np.float32)\n",
    "\n",
    "        # To tensor (C,H,W)\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1)          # (3,H,W)\n",
    "        mask = torch.from_numpy(mask).unsqueeze(0)            # (1,H,W)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DATASET PATHS (EDIT THIS)\n",
    "# =========================\n",
    "IMG_DIR  = \"path/to/BUS-BRA/Images\"\n",
    "MASK_DIR = \"path/to/BUS-BRA/Masks\"\n",
    "\n",
    "\n",
    "images = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
    "masks  = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "\n",
    "assert len(images) == len(masks) and len(images) > 0, \"Images/Masks count mismatch or empty!\"\n",
    "\n",
    "df = pd.DataFrame({\"image\": images, \"mask\": masks})\n",
    "print(f\"Total: {len(df)} image-mask pairs\")\n",
    "\n",
    "# =========================\n",
    "# Train/Val/Test = 70/15/15\n",
    "# =========================\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42, shuffle=True)\n",
    "val_df,   test_df = train_test_split(temp_df, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "train_dataset = BUSIDataset(train_df)\n",
    "val_dataset   = BUSIDataset(val_df)\n",
    "test_dataset  = BUSIDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=8, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# =========================\n",
    "# Loss function: Weighted BCE + Dice\n",
    "# =========================\n",
    "def weighted_bce_dice_loss(pred, target):\n",
    "    t = target.view(-1)\n",
    "    num_pos = torch.clamp(t.sum(), min=0.)\n",
    "    num_tot = t.numel()\n",
    "    num_neg = num_tot - num_pos\n",
    "    if num_pos <= 0:\n",
    "        pos_weight = torch.tensor(1.0, device=target.device)\n",
    "    else:\n",
    "        pos_weight = (num_neg / (num_pos + 1e-6)).to(target.device)\n",
    "\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target, pos_weight=pos_weight)\n",
    "\n",
    "    p = torch.sigmoid(pred)\n",
    "    intersection = (p * target).sum(dim=(1,2,3))\n",
    "    denom = p.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3)) + 1e-6\n",
    "    dice = (2.0 * intersection + 1e-6) / denom\n",
    "    dice_loss = 1.0 - dice.mean()\n",
    "\n",
    "    return bce + dice_loss\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_metrics_from_logits(pred_logits, masks):\n",
    "    probs = torch.sigmoid(pred_logits)\n",
    "    preds = (probs > 0.5).float()\n",
    "\n",
    "    TP = (preds * masks).sum().item()\n",
    "    FP = (preds * (1 - masks)).sum().item()\n",
    "    FN = ((1 - preds) * masks).sum().item()\n",
    "    TN = ((1 - preds) * (1 - masks)).sum().item()\n",
    "\n",
    "    eps = 1e-7\n",
    "    precision = TP / (TP + FP + eps)\n",
    "    recall    = TP / (TP + FN + eps)\n",
    "    f1        = 2 * precision * recall / (precision + recall + eps)\n",
    "    iou       = TP / (TP + FP + FN + eps)\n",
    "    dice      = (2 * TP) / (2 * TP + FP + FN + eps)\n",
    "    accuracy  = (TP + TN) / (TP + TN + FP + FN + eps)\n",
    "    return precision, recall, f1, iou, dice, accuracy\n",
    "\n",
    "# =========================\n",
    "# Training / Eval loops\n",
    "# =========================\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_sum = 0.0\n",
    "    for imgs, masks in loader:\n",
    "        imgs   = imgs.to(device, non_blocking=True)\n",
    "        masks  = masks.to(device, non_blocking=True).float()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(imgs)\n",
    "        loss = weighted_bce_dice_loss(logits, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_loss(model, loader, device):\n",
    "    model.eval()\n",
    "    loss_sum = 0.0\n",
    "    for imgs, masks in loader:\n",
    "        imgs   = imgs.to(device, non_blocking=True)\n",
    "        masks  = masks.to(device, non_blocking=True).float()\n",
    "        logits = model(imgs)\n",
    "        loss = weighted_bce_dice_loss(logits, masks)\n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / max(1, len(loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_metrics(model, loader, device):\n",
    "    model.eval()\n",
    "    totals = {\"precision\":0.0, \"recall\":0.0, \"f1\":0.0, \"iou\":0.0, \"dice\":0.0, \"accuracy\":0.0}\n",
    "    n = 0\n",
    "    for imgs, masks in loader:\n",
    "        imgs   = imgs.to(device, non_blocking=True)\n",
    "        masks  = masks.to(device, non_blocking=True).float()\n",
    "        logits = model(imgs)\n",
    "        p, r, f1, iou, d, acc = compute_metrics_from_logits(logits, masks)\n",
    "        totals[\"precision\"] += p\n",
    "        totals[\"recall\"]    += r\n",
    "        totals[\"f1\"]        += f1\n",
    "        totals[\"iou\"]       += iou\n",
    "        totals[\"dice\"]      += d\n",
    "        totals[\"accuracy\"]  += acc\n",
    "        n += 1\n",
    "    for k in totals:\n",
    "        totals[k] /= max(1, n)\n",
    "    return totals\n",
    "\n",
    "def run_training(encoder_name, train_loader, val_loader, test_loader, device, epochs=20, lr=1e-4):\n",
    "    model = smp.Unet(\n",
    "        encoder_name=encoder_name,\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    print(f\"\\n=== Training {encoder_name.upper()} for {epochs} epochs ===\")\n",
    "    for epoch in range(1, epochs+1):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        va_loss = eval_loss(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch:02d}/{epochs} | Train Loss: {tr_loss:.4f} | Val Loss: {va_loss:.4f}\")\n",
    "\n",
    "    test_metrics = evaluate_metrics(model, test_loader, device)\n",
    "    return model, test_metrics\n",
    "\n",
    "# =========================\n",
    "# Run models\n",
    "# =========================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "encoders_to_test = [\n",
    "    \"resnet34\", \n",
    "    \"resnet50\",\n",
    "    \"densenet121\",\n",
    "    \"efficientnet-b0\",\n",
    "    \"efficientnet-b1\",\n",
    "    \"efficientnet-b2\",\n",
    "    \"efficientnet-b3\",\n",
    "    \"efficientnet-b4\",\n",
    "    \"efficientnet-b5\",\n",
    "    \"efficientnet-b6\",\n",
    "    \"efficientnet-b7\",\n",
    "    \"vgg19_bn\",\n",
    "    \"mobilenet_v2\",   \n",
    "    \"inceptionresnetv2\",\"inceptionv4\"\n",
    "    \"mit_b0\",\"mit_b1\",\"mit_b2\",\"mit_b3\",\"mit_b4\",\"mit_b5\"          \n",
    "]\n",
    "    \n",
    "results = []\n",
    "for enc in encoders_to_test:\n",
    "    print(f\"\\nğŸš€ Training with encoder: {enc}\")\n",
    "    _, test_metrics = run_training(\n",
    "        enc, train_loader, val_loader, test_loader, device,\n",
    "        epochs=20,\n",
    "        lr=1e-4\n",
    "    )\n",
    "    results.append({\n",
    "        \"Model\": enc,\n",
    "        \"Precision\": test_metrics[\"precision\"],\n",
    "        \"Recall\":    test_metrics[\"recall\"],\n",
    "        \"F1\":        test_metrics[\"f1\"],\n",
    "        \"IoU\":       test_metrics[\"iou\"],\n",
    "        \"Dice\":      test_metrics[\"dice\"],\n",
    "        \"Accuracy\":  test_metrics[\"accuracy\"]\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nğŸ“Š Final Comparison Results:\")\n",
    "print(df_results)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6972772,
     "sourceId": 12403154,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
